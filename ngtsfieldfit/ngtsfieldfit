#!/usr/bin/env python

from astropy.io import fits 
import numpy as np 
import os, sys
import os.path
import time
from tqdm import tqdm 
from multiprocessing import Pool
import multiprocessing

def write_lightcurves(i):
    # Firs tchange the working directory
    os.chdir(home + '/{:}/{:}'.format(prod_id, obj_ids[i]) )

    # Now check if it's there and skip
    if os.path.exists('ngts.lc') : return

    # Get the lightcurve data
    time, mag, mag_err = lightcurves.data[i]

    # Convert time to HJD from 
    time = time/ 86400. + 6658.5

    # Now save lightcurve
    np.savetxt('ngts.lc'.format(prod_id, obj_ids[i]), np.array([time.tolist(), mag.tolist(), mag_err.tolist(), mag.tolist(), mag_err.tolist()]).T )
    
    # Now add to writing lightcurve pool
    
def bin_lightcurves(i):
    # First, cd to the directory
    os.chdir(home + '/{:}/{:}'.format(prod_id, obj_ids[i]) )

    # Now check if it's there and skip
    if (os.path.exists('2_min_lc.dat') and os.path.exists('30_min_lc.dat')) : return  

    # The wait for the file to be made by the "write_lightcurves" processes...
    while not os.path.exists('ngts.lc'):
        time.sleep(1)
    os.system('ngtsbin ngts.lc 2')
    os.system('ngtsbin ngts.lc 30')


def fit_lightcurve(i):
    # Get the object ID
    obj_id = info.data[i]["OBJ_ID"]

    # Change working directory to it
    os.chdir(home + '/{:}/{:}'.format(prod_id, obj_id) )

    # Get transit parameters
    period = info.data[i]["PERIOD"] / 86400.           # Period in days                '
    epoch = info.data[i]["EPOCH"] / 86400. + 6658.5    # epoch in HJD-2450000 / days
    width = info.data[i]["WIDTH"] /  86400.            # Width in days
    depth = info.data[i]["DEPTH"]* -1.                 # depth in mmag
    radius_1 = np.pi*width/period
    k = np.sqrt(depth)
    PEAK =info.data[i]["RANK"]

    # Now check if fit has been done
    if os.path.exists('chain_{:}.dat'.format(PEAK)): return  

    # Now wait for the lightcurve
    while not os.path.exists('30_min_lc.dat'):
        time.sleep(1)

    # Make the fitting call 
    os.system('ngtsfit --filename 30_min_lc.dat --t_zero {:.6f} --period {:.6f} --radius_1 {:.3f} --k {:.3f} --nsteps 10000 --burn_in 5000 --walkers 100 --output chain_{:}.dat'.format(epoch,period, radius_1, k, PEAK))

def corner_lightcurve(i):

    # Change working directory to it
    obj_id = info.data[i]["OBJ_ID"]
    os.chdir(home + '/{:}/{:}'.format(prod_id, obj_id) )

    # Get the peak for renaming 
    PEAK =info.data[i]["RANK"]

    # Check for skip
    if os.path.exists('ngtsfit_{:}.html'.format(PEAK)): return  


    # Now wait for the lightcurve
    while not os.path.exists('chain_{:}.dat'.format(PEAK)):
        time.sleep(1)

    # Now make and change to tmp directory to avoid thread races
    os.system('mkdir -p tmp_{:}'.format(PEAK))
    os.chdir('tmp_{:}'.format(PEAK))

    # Now make the plotting call, pipeing it to ngtslog and background since
    # it wont be as long as the fit (hopefully).
    os.system('ngtscorner ../chain_{:}.dat ../2_min_lc.dat ../30_min_lc.dat > ngtsfit.log'.format(PEAK))

    # Now rename files based on index
    os.system('cp ngtsfit_best_model.png ../ngtsfit_best_model_{:}.png'.format(PEAK))
    os.system('cp ngtsfit_corner_calculated_parameters.png ../ngtsfit_corner_calculated_parameters_{:}.png'.format(PEAK))
    os.system('cp ngtsfit_corner_fitted_parameters.png ../ngtsfit_corner_fitted_parameters_{:}.png'.format(PEAK))
    os.system('cp ngtsfit.log ../ngtsfit_{:}.log'.format(PEAK))
    os.system('cp ngtsfit.html ../ngtsfit_{:}.html'.format(PEAK))
    
    # now change back to home directory and delete the temp directory
    #os.chdir('..')
    #os.system('rm -r tmp_{:}'.format(PEAK))

    # Now remove the chain_{:}.dat to keep filespace at a minimum
    #os.system('rm chain_{:}.dat'.format(PEAK))

if __name__ == '__main__':

    # Load the fits file
    h = fits.open(sys.argv[1])

    # Now define a couple of paths 
    prod_id = str(h[0].header['PROD_ID'])
    print('Processing {:} [product ID {:}]'.format(h[0].header['FIELD'] +'_' +  h[0].header['TAG'], prod_id))

    # Now create the product ID folder
    # Run this on single thread since it's quick
    os.system('rm -r -f {:}'.format(prod_id))
    os.system('mkdir -p {:}'.format(prod_id))

    # Now we need to get a list of independent object IDs
    obj_ids = np.unique(h[4].data["OBJ_ID"])  
    print('\tCreating file structure... ', end=''); sys.stdout.flush()
    for i in range(len(obj_ids))[:] : os.system('mkdir {:}/{:}'.format(prod_id, obj_ids[i]))
    print('done.')

    # Create  this to allow multiprocessing
    home = os.getcwd()
    info = h[4]
    lightcurves = h[5]


    print('\tCreating lightcurve files... ', end=''); sys.stdout.flush()
    writing_pool = Pool(5)
    binning_pool = Pool(5)
    fitting_pool = Pool(5)
    corner_pool = Pool(5)

    writing_pool.map_async(write_lightcurves, range(len(obj_ids))[:])
    binning_pool.map_async(bin_lightcurves, range(len(obj_ids))[:])
    fitting_pool.map_async(fit_lightcurve, range(len(h[4].data["OBJ_ID"]))[:])                             
    corner_pool.map_async(corner_lightcurve, range(len(h[4].data["OBJ_ID"]))[:])

    writing_pool.close()
    writing_pool.join()
    binning_pool.close()
    binning_pool.join()
    fitting_pool.close()
    fitting_pool.join()
    corner_pool.close()
    corner_pool.join()

    os.chdir(home)
    print(' ... done.')

    # Now we need to cycle all the indexes
    for i in range(len(h[4].data))[:]:
        fit_lightcurve(i)
    os.chdir(home)
    print(' ... done.')
